import torch
import torch.nn as nn
import torch.nn.functional as F

from utils import DEVICE, GaussianNoise


class mccQNet(torch.nn.Module):
    def __init__(self, num_observations, num_actions):
        super(mccQNet, self).__init__()

        self.num_observations = num_observations
        self.num_actions = num_actions

        # remember to switch to eval mode when evaluating, as we use batch normalization
        self.batchnorm = nn.BatchNorm1d(num_observations+num_actions)
        self.fcl1 = nn.Linear(num_observations+num_actions, 100)
        self.fcl2 = nn.Linear(100,50)
        self.fcl3 = nn.Linear(50,1)

        # bounds of the network output (used for normalization)
        self.LOWER = -200
        self.UPPER = 200

    def normalize(self, x):
        """
        normalize [-LOWER,UPPER] into [-1,1]
        """
        return torch.clip(2*(x-self.LOWER)/(self.UPPER-self.LOWER)-1, min=-1, max=1)

    def denormalize(self, x):
        """
        denormalize [-1,1] into [-LOWER,UPPER]
        [-1,1]: network output
        [-LOWER, UPPER]: predicted reward
        """
        return (x+1)/2 * (self.UPPER-self.LOWER) + self.LOWER

    def forward(self, state):
        """
        return the Q-value for a given state x (obs+actions)
        :param state: B x obs+act matrix:
            first obs elements: observation
            last act element: action
        """
        x = torch.as_tensor(state, dtype=torch.float32, device=DEVICE)
        x = self.fcl1(x)
        x = F.relu(x)
        x = self.fcl2(x)
        x = F.relu(x)
        x = self.fcl3(x)
        x = torch.tanh(x)
        x = self.denormalize(x)

        return x
    
    def save(self, path):
        torch.save(self.state_dict(), path)
    
    def load(self, path):
        self.load_state_dict(torch.load(path))
        self.eval()


    
class mccPNet(torch.nn.Module):
    def __init__(self, num_observations, num_actions):
        super(mccPNet, self).__init__()

        self.num_observations = num_observations
        self.num_actions = num_actions

        # remember to switch to eval mode when evaluating, as we use batch normalization
        self.batchnorm = nn.BatchNorm1d(num_observations)
        self.fcl1 = nn.Linear(num_observations, 100)
        self.fcl2 = nn.Linear(100,50)
        self.fcl3 = nn.Linear(50,num_actions)

        self.noise_scheduler = GaussianNoise(std=0.1, shape=(num_actions,))

    def forward(self, obs):
        """
        return the action with lowest q-value for a given obs x
        :param obs: B x obs matrix
        """
        x = torch.as_tensor(obs, dtype=torch.float32, device=DEVICE)
        x = self.fcl1(x)
        x = F.relu(x)
        x = self.fcl2(x)
        x = F.relu(x)
        x = self.fcl3(x)
        x = torch.tanh(x)       #because the actions are in [-1,1]

        return x
    
    def select_action(self, obs, sigma=1):
        """
        select an action based on parameter sigma:
            net_output + sigma*noise
        where noise is generated by noise_scheduler (Ornstein-Uhlenbeck process)
        """

        actions = self.forward(obs)
        actions_plus_noise = actions + sigma * self.noise_scheduler.step()
        return torch.clamp(actions_plus_noise, min=-1, max=1)

    def save(self, path):
        torch.save(self.state_dict(), path)
    
    def load(self, path):
        self.load_state_dict(torch.load(path))
        self.eval()